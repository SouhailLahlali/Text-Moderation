# Text Toxicity Detector

A Python application that detects toxicity in text and classifies it as **SFW (Safe For Work)** or **NSFW (Not Safe For Work)**. This project helps identify harmful or inappropriate content in textual data.

---

## Features

- Detect toxic or offensive language in text.
- Classify text as SFW or NSFW.
- Easy-to-use Python interface.
- Can be integrated into chat apps, forums, or moderation tools.

---

